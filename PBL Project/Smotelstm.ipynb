{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed520d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c59734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and Preprocess Data\n",
    "data = pd.read_csv('landslidedata.csv')\n",
    "attributes = ['TEMP_MAX', 'TEMP_MIN', 'PRECIPITATION', 'SPECIFIC_HUMIDITY',\n",
    "              'RELATIVE_HUMIDITY', 'WIND_MIN', 'WIND_MAX',\n",
    "              'EARTHQUAKE_DEPTH', 'EARTHQUAKE_MAGNITUDE' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c328ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data[attributes] = scaler.fit_transform(data[attributes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d386614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>TEMP_MAX</th>\n",
       "      <th>TEMP_MIN</th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>RELATIVE_HUMIDITY</th>\n",
       "      <th>SPECIFIC_HUMIDITY</th>\n",
       "      <th>WIND_MIN</th>\n",
       "      <th>WIND_MAX</th>\n",
       "      <th>EARTHQUAKE_DEPTH</th>\n",
       "      <th>EARTHQUAKE_MAGNITUDE</th>\n",
       "      <th>MARKING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10947</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0.201843</td>\n",
       "      <td>0.213046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830816</td>\n",
       "      <td>0.319088</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.215166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0.225712</td>\n",
       "      <td>0.304552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838833</td>\n",
       "      <td>0.353751</td>\n",
       "      <td>0.117043</td>\n",
       "      <td>0.224645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10949</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.193049</td>\n",
       "      <td>0.243078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833023</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.069815</td>\n",
       "      <td>0.181043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>0.155779</td>\n",
       "      <td>0.132802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807576</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.162218</td>\n",
       "      <td>0.234123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0.234925</td>\n",
       "      <td>0.233224</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>0.755287</td>\n",
       "      <td>0.321937</td>\n",
       "      <td>0.045175</td>\n",
       "      <td>0.232227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.224456</td>\n",
       "      <td>0.298921</td>\n",
       "      <td>0.034565</td>\n",
       "      <td>0.929584</td>\n",
       "      <td>0.405983</td>\n",
       "      <td>0.227926</td>\n",
       "      <td>0.261611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10953</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0.158710</td>\n",
       "      <td>0.259972</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.883105</td>\n",
       "      <td>0.339031</td>\n",
       "      <td>0.232033</td>\n",
       "      <td>0.233175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.248325</td>\n",
       "      <td>0.162834</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.827911</td>\n",
       "      <td>0.336182</td>\n",
       "      <td>0.209446</td>\n",
       "      <td>0.284360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0.239531</td>\n",
       "      <td>0.235101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832210</td>\n",
       "      <td>0.371320</td>\n",
       "      <td>0.039014</td>\n",
       "      <td>0.298578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.306114</td>\n",
       "      <td>0.392304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840228</td>\n",
       "      <td>0.426401</td>\n",
       "      <td>0.151951</td>\n",
       "      <td>0.185782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       YEAR  MONTH  DAY  TEMP_MAX  TEMP_MIN  PRECIPITATION  RELATIVE_HUMIDITY  \\\n",
       "10947  2019     12   22  0.201843  0.213046       0.000000           0.830816   \n",
       "10948  2019     12   23  0.225712  0.304552       0.000000           0.838833   \n",
       "10949  2019     12   24  0.193049  0.243078       0.000000           0.833023   \n",
       "10950  2019     12   25  0.155779  0.132802       0.000000           0.807576   \n",
       "10951  2019     12   26  0.234925  0.233224       0.015398           0.755287   \n",
       "10952  2019     12   27  0.224456  0.298921       0.034565           0.929584   \n",
       "10953  2019     12   28  0.158710  0.259972       0.000796           0.883105   \n",
       "10954  2019     12   29  0.248325  0.162834       0.000159           0.827911   \n",
       "10955  2019     12   30  0.239531  0.235101       0.000000           0.832210   \n",
       "10956  2019     12   31  0.306114  0.392304       0.000000           0.840228   \n",
       "\n",
       "       SPECIFIC_HUMIDITY  WIND_MIN  WIND_MAX  EARTHQUAKE_DEPTH  \\\n",
       "10947           0.319088  0.008214  0.215166               0.0   \n",
       "10948           0.353751  0.117043  0.224645               0.0   \n",
       "10949           0.333333  0.069815  0.181043               0.0   \n",
       "10950           0.290123  0.162218  0.234123               0.0   \n",
       "10951           0.321937  0.045175  0.232227               0.0   \n",
       "10952           0.405983  0.227926  0.261611               0.0   \n",
       "10953           0.339031  0.232033  0.233175               0.0   \n",
       "10954           0.336182  0.209446  0.284360               0.0   \n",
       "10955           0.371320  0.039014  0.298578               0.0   \n",
       "10956           0.426401  0.151951  0.185782               0.0   \n",
       "\n",
       "       EARTHQUAKE_MAGNITUDE  MARKING  \n",
       "10947                   0.0        0  \n",
       "10948                   0.0        0  \n",
       "10949                   0.0        0  \n",
       "10950                   0.0        0  \n",
       "10951                   0.0        0  \n",
       "10952                   0.0        1  \n",
       "10953                   0.0        0  \n",
       "10954                   0.0        0  \n",
       "10955                   0.0        0  \n",
       "10956                   0.0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdaa5f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X = data[attributes].values\n",
    "y = data['MARKING'].values  # Assuming you have a 'LANDSLIDE_LABEL' column for labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50435049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5297, 1: 2372}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, count = np.unique(y_train, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "y_train_dict_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6231e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state =12, sampling_strategy = 1.0)\n",
    "# x_train_result, y_train_result = sm.fit_sample(X_train, y_train)\n",
    "x_train_result, y_train_result = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54667e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5297, 1: 5297}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, count = np.unique(y_train_result, return_counts=True)\n",
    "y_train_smote_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "y_train_smote_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f728d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for LSTM input\n",
    "x_train_result = x_train_result.reshape(x_train_result.shape[0], x_train_result.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc04e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the LSTM Model\n",
    "lstm = Sequential([\n",
    "    LSTM(units=50, activation='relu', input_shape=(x_train_result.shape[1], 1)),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c23238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "332/332 [==============================] - 8s 11ms/step - loss: 0.5433 - accuracy: 0.7016\n",
      "Epoch 2/10\n",
      "332/332 [==============================] - 3s 10ms/step - loss: 0.2674 - accuracy: 0.8890\n",
      "Epoch 3/10\n",
      "332/332 [==============================] - 4s 11ms/step - loss: 0.1955 - accuracy: 0.9285\n",
      "Epoch 4/10\n",
      "332/332 [==============================] - 4s 11ms/step - loss: 0.1944 - accuracy: 0.9259\n",
      "Epoch 5/10\n",
      "332/332 [==============================] - 3s 10ms/step - loss: 0.1759 - accuracy: 0.9375\n",
      "Epoch 6/10\n",
      "332/332 [==============================] - 4s 11ms/step - loss: 0.1678 - accuracy: 0.9391\n",
      "Epoch 7/10\n",
      "332/332 [==============================] - 4s 11ms/step - loss: 0.1761 - accuracy: 0.9329\n",
      "Epoch 8/10\n",
      "332/332 [==============================] - 4s 11ms/step - loss: 0.1514 - accuracy: 0.9455\n",
      "Epoch 9/10\n",
      "332/332 [==============================] - 4s 11ms/step - loss: 0.1541 - accuracy: 0.9416\n",
      "Epoch 10/10\n",
      "332/332 [==============================] - 4s 11ms/step - loss: 0.1357 - accuracy: 0.9497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25b8c44fcd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Compile and Train the Model\n",
    "lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm.fit(x_train_result.reshape(x_train_result.shape[0], X_train.shape[1], 1), y_train_result, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "177936b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1401 - accuracy: 0.9377\n",
      "Accuracy: 93.77%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = lstm.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff2be050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1a8ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lstm.pickle', 'wb') as f:\n",
    "    pickle.dump(lstm , f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a86e91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lstm.pickle', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aaed028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.sequential.Sequential object at 0x0000025B8D8FF4D0>\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbe6ed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter new attributes:\n",
      "Enter value for TEMP_MAX: 33\n",
      "Enter value for TEMP_MIN: 25\n",
      "Enter value for PRECIPITATION: 2.3\n",
      "Enter value for SPECIFIC_HUMIDITY: 78\n",
      "Enter value for RELATIVE_HUMIDITY: 23\n",
      "Enter value for WIND_MIN: 2.3\n",
      "Enter value for WIND_MAX: 5.5\n",
      "Enter value for EARTHQUAKE_DEPTH: 0\n",
      "Enter value for EARTHQUAKE_MAGNITUDE: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 525ms/step\n",
      "Predicted Marking: Landslide\n",
      "Do you want to continue? (yes/no): no\n"
     ]
    }
   ],
   "source": [
    "# Initialize a flag to continue taking input\n",
    "continue_input = True\n",
    "\n",
    "while continue_input:\n",
    "    new_attributes = []\n",
    "\n",
    "    print(\"Enter new attributes:\")\n",
    "    for attribute in attributes:\n",
    "        value = float(input(f\"Enter value for {attribute}: \"))\n",
    "        new_attributes.append(value)\n",
    "\n",
    "    # Normalize the new attributes using the same scaler\n",
    "    new_attributes = np.array(new_attributes).reshape(1, -1)\n",
    "    new_attributes = scaler.transform(new_attributes)\n",
    "\n",
    "    # Reshape the new attributes for LSTM input\n",
    "    new_attributes = new_attributes.reshape(1, new_attributes.shape[1], 1)\n",
    "\n",
    "    # Predict marking for new attributes\n",
    "    predicted_prob = loaded_model.predict(new_attributes)\n",
    "    predicted_marking = \"Landslide\" if predicted_prob >= 0.5 else \"No Landslide\"\n",
    "    print(\"Predicted Marking:\", predicted_marking)\n",
    "\n",
    "    # Ask if user wants to continue\n",
    "    user_input = input(\"Do you want to continue? (yes/no): \")\n",
    "    if user_input.lower() != 'yes':\n",
    "        continue_input = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
