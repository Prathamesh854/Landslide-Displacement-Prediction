{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723b8bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c2b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and Preprocess Data\n",
    "data = pd.read_csv('landslidedata.csv')\n",
    "attributes = ['TEMP_MAX', 'TEMP_MIN', 'PRECIPITATION', 'SPECIFIC_HUMIDITY',\n",
    "              'RELATIVE_HUMIDITY', 'WIND_MIN', 'WIND_MAX',\n",
    "              'EARTHQUAKE_DEPTH', 'EARTHQUAKE_MAGNITUDE' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a2c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data[attributes] = scaler.fit_transform(data[attributes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb47cfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>TEMP_MAX</th>\n",
       "      <th>TEMP_MIN</th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>RELATIVE_HUMIDITY</th>\n",
       "      <th>SPECIFIC_HUMIDITY</th>\n",
       "      <th>WIND_MIN</th>\n",
       "      <th>WIND_MAX</th>\n",
       "      <th>EARTHQUAKE_DEPTH</th>\n",
       "      <th>EARTHQUAKE_MAGNITUDE</th>\n",
       "      <th>MARKING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10947</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0.201843</td>\n",
       "      <td>0.213046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830816</td>\n",
       "      <td>0.319088</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.215166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0.225712</td>\n",
       "      <td>0.304552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838833</td>\n",
       "      <td>0.353751</td>\n",
       "      <td>0.117043</td>\n",
       "      <td>0.224645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10949</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.193049</td>\n",
       "      <td>0.243078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833023</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.069815</td>\n",
       "      <td>0.181043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>0.155779</td>\n",
       "      <td>0.132802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807576</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.162218</td>\n",
       "      <td>0.234123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0.234925</td>\n",
       "      <td>0.233224</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>0.755287</td>\n",
       "      <td>0.321937</td>\n",
       "      <td>0.045175</td>\n",
       "      <td>0.232227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.224456</td>\n",
       "      <td>0.298921</td>\n",
       "      <td>0.034565</td>\n",
       "      <td>0.929584</td>\n",
       "      <td>0.405983</td>\n",
       "      <td>0.227926</td>\n",
       "      <td>0.261611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10953</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0.158710</td>\n",
       "      <td>0.259972</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.883105</td>\n",
       "      <td>0.339031</td>\n",
       "      <td>0.232033</td>\n",
       "      <td>0.233175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.248325</td>\n",
       "      <td>0.162834</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.827911</td>\n",
       "      <td>0.336182</td>\n",
       "      <td>0.209446</td>\n",
       "      <td>0.284360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0.239531</td>\n",
       "      <td>0.235101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832210</td>\n",
       "      <td>0.371320</td>\n",
       "      <td>0.039014</td>\n",
       "      <td>0.298578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.306114</td>\n",
       "      <td>0.392304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840228</td>\n",
       "      <td>0.426401</td>\n",
       "      <td>0.151951</td>\n",
       "      <td>0.185782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       YEAR  MONTH  DAY  TEMP_MAX  TEMP_MIN  PRECIPITATION  RELATIVE_HUMIDITY  \\\n",
       "10947  2019     12   22  0.201843  0.213046       0.000000           0.830816   \n",
       "10948  2019     12   23  0.225712  0.304552       0.000000           0.838833   \n",
       "10949  2019     12   24  0.193049  0.243078       0.000000           0.833023   \n",
       "10950  2019     12   25  0.155779  0.132802       0.000000           0.807576   \n",
       "10951  2019     12   26  0.234925  0.233224       0.015398           0.755287   \n",
       "10952  2019     12   27  0.224456  0.298921       0.034565           0.929584   \n",
       "10953  2019     12   28  0.158710  0.259972       0.000796           0.883105   \n",
       "10954  2019     12   29  0.248325  0.162834       0.000159           0.827911   \n",
       "10955  2019     12   30  0.239531  0.235101       0.000000           0.832210   \n",
       "10956  2019     12   31  0.306114  0.392304       0.000000           0.840228   \n",
       "\n",
       "       SPECIFIC_HUMIDITY  WIND_MIN  WIND_MAX  EARTHQUAKE_DEPTH  \\\n",
       "10947           0.319088  0.008214  0.215166               0.0   \n",
       "10948           0.353751  0.117043  0.224645               0.0   \n",
       "10949           0.333333  0.069815  0.181043               0.0   \n",
       "10950           0.290123  0.162218  0.234123               0.0   \n",
       "10951           0.321937  0.045175  0.232227               0.0   \n",
       "10952           0.405983  0.227926  0.261611               0.0   \n",
       "10953           0.339031  0.232033  0.233175               0.0   \n",
       "10954           0.336182  0.209446  0.284360               0.0   \n",
       "10955           0.371320  0.039014  0.298578               0.0   \n",
       "10956           0.426401  0.151951  0.185782               0.0   \n",
       "\n",
       "       EARTHQUAKE_MAGNITUDE  MARKING  \n",
       "10947                   0.0        0  \n",
       "10948                   0.0        0  \n",
       "10949                   0.0        0  \n",
       "10950                   0.0        0  \n",
       "10951                   0.0        0  \n",
       "10952                   0.0        1  \n",
       "10953                   0.0        0  \n",
       "10954                   0.0        0  \n",
       "10955                   0.0        0  \n",
       "10956                   0.0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ff171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X = data[attributes].values\n",
    "y = data['MARKING'].values  # Assuming you have a 'LANDSLIDE_LABEL' column for labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3bc0682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5297, 1: 2372}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, count = np.unique(y_train, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "y_train_dict_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305d1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state =12, sampling_strategy = 1.0)\n",
    "# x_train_result, y_train_result = sm.fit_sample(X_train, y_train)\n",
    "x_train_result, y_train_result = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad62f7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5297, 1: 5297}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, count = np.unique(y_train_result, return_counts=True)\n",
    "y_train_smote_value_count = {k:v for (k,v) in zip(unique,count)}\n",
    "y_train_smote_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f755ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for LSTM input\n",
    "x_train_result = x_train_result.reshape(x_train_result.shape[0], x_train_result.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50179aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ff58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "bilstm = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a287929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Bidirectional LSTM layer with 128 units and 'relu' activation\n",
    "bilstm.add(Bidirectional(LSTM(128, activation='relu', input_shape=(x_train_result.shape[1], 1))))\n",
    "\n",
    "# Add more layers\n",
    "bilstm.add(Dense(64, activation='relu'))  # Adding a Dense layer with 64 units and 'relu' activation\n",
    "bilstm.add(Dense(32, activation='relu'))  # Adding another Dense layer with 32 units and 'relu' activation\n",
    "\n",
    "# Output layer\n",
    "bilstm.add(Dense(1, activation='sigmoid'))  # Output layer with 1 unit and 'sigmoid' activation\n",
    "\n",
    "# Compile the model\n",
    "bilstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7430e97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "332/332 [==============================] - 20s 34ms/step - loss: 0.4006 - accuracy: 0.8155 - val_loss: 0.1832 - val_accuracy: 0.9328\n",
      "Epoch 2/50\n",
      "332/332 [==============================] - 9s 27ms/step - loss: 0.1801 - accuracy: 0.9285 - val_loss: 0.1203 - val_accuracy: 0.9595\n",
      "Epoch 3/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.1301 - accuracy: 0.9501 - val_loss: 0.1654 - val_accuracy: 0.9176\n",
      "Epoch 4/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.1136 - accuracy: 0.9546 - val_loss: 0.0863 - val_accuracy: 0.9678\n",
      "Epoch 5/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0968 - accuracy: 0.9619 - val_loss: 0.2639 - val_accuracy: 0.8990\n",
      "Epoch 6/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.1253 - accuracy: 0.9509 - val_loss: 0.0694 - val_accuracy: 0.9726\n",
      "Epoch 7/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.1043 - accuracy: 0.9579 - val_loss: 0.2584 - val_accuracy: 0.8960\n",
      "Epoch 8/50\n",
      "332/332 [==============================] - 10s 31ms/step - loss: 0.0922 - accuracy: 0.9638 - val_loss: 0.1734 - val_accuracy: 0.9209\n",
      "Epoch 9/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.1099 - accuracy: 0.9594 - val_loss: 0.1034 - val_accuracy: 0.9523\n",
      "Epoch 10/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0869 - accuracy: 0.9648 - val_loss: 0.0774 - val_accuracy: 0.9653\n",
      "Epoch 11/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0774 - accuracy: 0.9677 - val_loss: 0.0694 - val_accuracy: 0.9696\n",
      "Epoch 12/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0705 - accuracy: 0.9727 - val_loss: 0.0530 - val_accuracy: 0.9821\n",
      "Epoch 13/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0777 - accuracy: 0.9691 - val_loss: 0.1193 - val_accuracy: 0.9425\n",
      "Epoch 14/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0681 - accuracy: 0.9720 - val_loss: 0.0775 - val_accuracy: 0.9626\n",
      "Epoch 15/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0760 - accuracy: 0.9695 - val_loss: 0.1999 - val_accuracy: 0.9215\n",
      "Epoch 16/50\n",
      "332/332 [==============================] - 10s 31ms/step - loss: 0.0758 - accuracy: 0.9686 - val_loss: 0.0605 - val_accuracy: 0.9735\n",
      "Epoch 17/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0676 - accuracy: 0.9728 - val_loss: 0.0496 - val_accuracy: 0.9796\n",
      "Epoch 18/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0741 - accuracy: 0.9711 - val_loss: 0.0616 - val_accuracy: 0.9760\n",
      "Epoch 19/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0698 - accuracy: 0.9700 - val_loss: 0.0487 - val_accuracy: 0.9824\n",
      "Epoch 20/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0702 - accuracy: 0.9725 - val_loss: 0.3060 - val_accuracy: 0.8939\n",
      "Epoch 21/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0678 - accuracy: 0.9725 - val_loss: 0.0714 - val_accuracy: 0.9653\n",
      "Epoch 22/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0673 - accuracy: 0.9729 - val_loss: 0.0613 - val_accuracy: 0.9790\n",
      "Epoch 23/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0648 - accuracy: 0.9747 - val_loss: 0.0481 - val_accuracy: 0.9799\n",
      "Epoch 24/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0768 - accuracy: 0.9684 - val_loss: 0.1988 - val_accuracy: 0.9212\n",
      "Epoch 25/50\n",
      "332/332 [==============================] - 10s 30ms/step - loss: 0.0651 - accuracy: 0.9728 - val_loss: 0.0765 - val_accuracy: 0.9632\n",
      "Epoch 26/50\n",
      "332/332 [==============================] - 10s 31ms/step - loss: 0.0585 - accuracy: 0.9762 - val_loss: 0.1140 - val_accuracy: 0.9516\n",
      "Epoch 27/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0782 - accuracy: 0.9695 - val_loss: 0.0893 - val_accuracy: 0.9553\n",
      "Epoch 28/50\n",
      "332/332 [==============================] - 9s 27ms/step - loss: 0.0663 - accuracy: 0.9715 - val_loss: 0.0832 - val_accuracy: 0.9605\n",
      "Epoch 29/50\n",
      "332/332 [==============================] - 9s 27ms/step - loss: 0.0695 - accuracy: 0.9719 - val_loss: 0.0500 - val_accuracy: 0.9811\n",
      "Epoch 30/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0640 - accuracy: 0.9748 - val_loss: 0.0484 - val_accuracy: 0.9802\n",
      "Epoch 31/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0685 - accuracy: 0.9734 - val_loss: 0.0704 - val_accuracy: 0.9665\n",
      "Epoch 32/50\n",
      "332/332 [==============================] - 8s 26ms/step - loss: 0.0571 - accuracy: 0.9774 - val_loss: 0.1454 - val_accuracy: 0.9392\n",
      "Epoch 33/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0631 - accuracy: 0.9744 - val_loss: 0.0492 - val_accuracy: 0.9790\n",
      "Epoch 34/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0590 - accuracy: 0.9756 - val_loss: 0.1125 - val_accuracy: 0.9440\n",
      "Epoch 35/50\n",
      "332/332 [==============================] - 9s 27ms/step - loss: 0.0554 - accuracy: 0.9778 - val_loss: 0.0505 - val_accuracy: 0.9805\n",
      "Epoch 36/50\n",
      "332/332 [==============================] - 9s 27ms/step - loss: 0.0575 - accuracy: 0.9766 - val_loss: 0.0753 - val_accuracy: 0.9644\n",
      "Epoch 37/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0518 - accuracy: 0.9796 - val_loss: 0.0621 - val_accuracy: 0.9726\n",
      "Epoch 38/50\n",
      "332/332 [==============================] - 9s 26ms/step - loss: 0.0539 - accuracy: 0.9783 - val_loss: 0.1675 - val_accuracy: 0.9346\n",
      "Epoch 39/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0713 - accuracy: 0.9719 - val_loss: 0.0555 - val_accuracy: 0.9787\n",
      "Epoch 40/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0623 - accuracy: 0.9745 - val_loss: 0.0989 - val_accuracy: 0.9574\n",
      "Epoch 41/50\n",
      "332/332 [==============================] - 9s 27ms/step - loss: 0.0555 - accuracy: 0.9785 - val_loss: 0.3942 - val_accuracy: 0.8984\n",
      "Epoch 42/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0530 - accuracy: 0.9802 - val_loss: 0.0527 - val_accuracy: 0.9757\n",
      "Epoch 43/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0753 - accuracy: 0.9728 - val_loss: 0.0572 - val_accuracy: 0.9763\n",
      "Epoch 44/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0507 - accuracy: 0.9816 - val_loss: 0.0472 - val_accuracy: 0.9799\n",
      "Epoch 45/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0581 - accuracy: 0.9771 - val_loss: 0.1056 - val_accuracy: 0.9526\n",
      "Epoch 46/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0433 - accuracy: 0.9820 - val_loss: 0.0394 - val_accuracy: 0.9836\n",
      "Epoch 47/50\n",
      "332/332 [==============================] - 9s 29ms/step - loss: 0.0725 - accuracy: 0.9724 - val_loss: 0.1123 - val_accuracy: 0.9474\n",
      "Epoch 48/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0563 - accuracy: 0.9790 - val_loss: 0.0618 - val_accuracy: 0.9726\n",
      "Epoch 49/50\n",
      "332/332 [==============================] - 9s 28ms/step - loss: 0.0556 - accuracy: 0.9764 - val_loss: 0.0411 - val_accuracy: 0.9854\n",
      "Epoch 50/50\n",
      "332/332 [==============================] - 10s 29ms/step - loss: 0.0620 - accuracy: 0.9762 - val_loss: 0.0384 - val_accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2006d666c10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "bilstm.fit(x_train_result, y_train_result, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b579e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 1s 11ms/step - loss: 0.0384 - accuracy: 0.9857\n",
      "Accuracy: 98.57%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = bilstm.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b0ef8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21e3236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open('bilstm.pickle', 'wb') as f:\n",
    "    dill.dump(bilstm, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b0e3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bilstm.pickle', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1e0bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.sequential.Sequential object at 0x000001BE6E827190>\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ad9bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict marking for new attributes\n",
    "def predict_marking(attributes):\n",
    "    # Normalize the attributes using the loaded scaler\n",
    "    attributes_scaled = scaler.transform([attributes])\n",
    "\n",
    "    # Reshape the attributes for LSTM input\n",
    "    attributes_bilstm = attributes_scaled.reshape(1, attributes_scaled.shape[1], 1)\n",
    "\n",
    "    # Predict marking for new attributes\n",
    "    predicted_prob = loaded_model.predict(attributes_bilstm)\n",
    "    predicted_marking = \"Landslide\" if predicted_prob >= 0.5 else \"No Landslide\"\n",
    "\n",
    "    return predicted_marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7152fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter new attributes:\n",
      "Enter value for TEMP_MAX: 39\n",
      "Enter value for TEMP_MIN: 25\n",
      "Enter value for PRECIPITATION: 7\n",
      "Enter value for SPECIFIC_HUMIDITY: 75\n",
      "Enter value for RELATIVE_HUMIDITY: 12\n",
      "Enter value for WIND_MIN: 2.5\n",
      "Enter value for WIND_MAX: 3.5\n",
      "Enter value for EARTHQUAKE_DEPTH: 0\n",
      "Enter value for EARTHQUAKE_MAGNITUDE: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "Predicted Marking: Landslide\n"
     ]
    }
   ],
   "source": [
    "# Initialize a flag to continue taking input\n",
    "continue_input = True\n",
    "\n",
    "while continue_input:\n",
    "    new_attributes = []\n",
    "\n",
    "    print(\"Enter new attributes:\")\n",
    "    for attribute in attributes:\n",
    "        value = float(input(f\"Enter value for {attribute}: \"))\n",
    "        new_attributes.append(value)\n",
    "\n",
    "    # Predict marking for new attributes\n",
    "    predicted_marking = predict_marking(new_attributes)\n",
    "    print(\"Predicted Marking:\", predicted_marking)\n",
    "\n",
    "    # Ask if user wants to continue\n",
    "    user_input = input(\"Do you want to continue? (yes/no): \")\n",
    "    if user_input.lower() != 'yes':\n",
    "        continue_input = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5708798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
